{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"LiarPantsFire-Multi\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/LiarPantsFire_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          statement        label  \\\n",
       "0   2635.json  Says the Annies List political group supports ...        false   \n",
       "1  10540.json  When did the decline of coal start? It started...    half-true   \n",
       "2    324.json  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
       "3   1123.json  Health care reform legislation is likely to ma...        false   \n",
       "4   9028.json  The economic turnaround started at the end of ...    half-true   \n",
       "\n",
       "         tvt2      tvt2_1      tvt2_2      tvt2_3  \n",
       "0  validation  validation    training    training  \n",
       "1    training    training  validation    training  \n",
       "2    training    training  validation  validation  \n",
       "3    training  validation    testting    training  \n",
       "4    training    training    testting    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/liarpantsfire_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 1, 3, 4, 1, 1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0aab2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attorney General Eric', 'Supreme Court nominee', 'wildly unpopular', 'Terry McAuliffe', 'For every one', 'takeover of healthcare', 'babies born in', 'and your doctor', '278,000 per job', 'voted six times']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/liarpantsfire_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['statement'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8598, 1519, 1)\n",
      "(2926, 1519, 1)\n",
      "(1267, 1519, 1)\n",
      "(8598,)\n",
      "(2926,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 19.002\n",
      "Saving after new best accuracy : 20.608\n",
      "Saving after new best accuracy : 20.643\n",
      "Saving after new best accuracy : 20.813\n",
      "Saving after new best accuracy : 20.95\n",
      "Saving after new best accuracy : 21.121\n",
      "Saving after new best accuracy : 21.531\n",
      "Saving after new best accuracy : 21.634\n",
      "Saving after new best accuracy : 21.77\n",
      "-- Epoch 50, Train Loss : 29.28094172477722, Test Loss : 1.757217526435852\n",
      "-- Epoch 100, Train Loss : 28.673104643821716, Test Loss : 1.7611110210418701\n",
      "-- Epoch 150, Train Loss : 28.48296546936035, Test Loss : 1.7636194229125977\n",
      "-- Epoch 200, Train Loss : 28.365896582603455, Test Loss : 1.7641990184783936\n",
      "-- Epoch 250, Train Loss : 28.28437316417694, Test Loss : 1.76453697681427\n",
      "-- Epoch 300, Train Loss : 28.186889052391052, Test Loss : 1.7657254934310913\n",
      "-- Epoch 350, Train Loss : 28.138433575630188, Test Loss : 1.766610860824585\n",
      "-- Epoch 400, Train Loss : 28.12253963947296, Test Loss : 1.7679704427719116\n",
      "-- Epoch 450, Train Loss : 28.110963702201843, Test Loss : 1.769248366355896\n",
      "-- Epoch 500, Train Loss : 28.101816773414612, Test Loss : 1.7699674367904663\n",
      "-- Epoch 550, Train Loss : 28.098751187324524, Test Loss : 1.7708678245544434\n",
      "-- Epoch 600, Train Loss : 28.093986868858337, Test Loss : 1.7705754041671753\n",
      "-- Epoch 650, Train Loss : 28.090763449668884, Test Loss : 1.7710775136947632\n",
      "-- Epoch 700, Train Loss : 28.091498374938965, Test Loss : 1.7704352140426636\n",
      "-- Epoch 750, Train Loss : 28.09201455116272, Test Loss : 1.7695432901382446\n",
      "-- Epoch 800, Train Loss : 28.08469271659851, Test Loss : 1.7710011005401611\n",
      "-- Epoch 850, Train Loss : 28.083898544311523, Test Loss : 1.770941972732544\n",
      "-- Epoch 900, Train Loss : 28.085943937301636, Test Loss : 1.769934892654419\n",
      "-- Epoch 950, Train Loss : 28.079147577285767, Test Loss : 1.771338701248169\n",
      "-- Epoch 1000, Train Loss : 28.07973802089691, Test Loss : 1.7701728343963623\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 373.92 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([2926])\n",
      "2926 vs 2926\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 31.892 %\n",
      "- Recall : 10.612 %\n",
      "- F1 : 0.15924\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 20.91 %\n",
      "- Recall : 94.527 %\n",
      "- F1 : 0.34245\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 50.0 %\n",
      "- Recall : 1.228 %\n",
      "- F1 : 0.02397\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 0.216 %\n",
      "- F1 : 0.0043\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 21.77 %\n",
      "- Precision : 33.8 %\n",
      "- Recall : 17.764 %\n",
      "- F1 : 0.23288\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 21.77, 33.8, 17.764, 0.23288, 31.892, 10.612, 0.15924, 20.91, 94.527, 0.34245, 50.0, 1.228, 0.02397, 0, 0.0, 0, 100.0, 0.216, 0.0043, 0, 0.0, 0, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1267])\n",
      "1267 vs 1267\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 37.681 %\n",
      "- Recall : 10.236 %\n",
      "- F1 : 0.16099\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 20.453 %\n",
      "- Recall : 93.846 %\n",
      "- F1 : 0.33586\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 20.0 %\n",
      "- Recall : 0.397 %\n",
      "- F1 : 0.00778\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 21.389 %\n",
      "- Precision : 13.022 %\n",
      "- Recall : 17.413 %\n",
      "- F1 : 0.14901\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 21.389, 13.022, 17.413, 0.14901, 37.681, 10.236, 0.16099, 20.453, 93.846, 0.33586, 20.0, 0.397, 0.00778, 0, 0.0, 0, 0, 0.0, 0, 0, 0.0, 0, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=6, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
