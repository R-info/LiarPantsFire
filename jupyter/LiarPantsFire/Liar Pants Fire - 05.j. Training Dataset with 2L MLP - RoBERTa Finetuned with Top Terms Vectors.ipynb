{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"LiarPantsFire-Multi\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/LiarPantsFire_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          statement        label  \\\n",
       "0   2635.json  Says the Annies List political group supports ...        false   \n",
       "1  10540.json  When did the decline of coal start? It started...    half-true   \n",
       "2    324.json  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
       "3   1123.json  Health care reform legislation is likely to ma...        false   \n",
       "4   9028.json  The economic turnaround started at the end of ...    half-true   \n",
       "\n",
       "         tvt2      tvt2_1      tvt2_2      tvt2_3  \n",
       "0  validation  validation    training    training  \n",
       "1    training    training  validation    training  \n",
       "2    training    training  validation  validation  \n",
       "3    training  validation    testting    training  \n",
       "4    training    training    testting    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/liarpantsfire_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 1, 3, 4, 1, 1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attorney General Eric', 'Supreme Court nominee', 'wildly unpopular', 'Terry McAuliffe', 'For every one', 'takeover of healthcare', 'babies born in', 'and your doctor', '278,000 per job', 'voted six times']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/liarpantsfire_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['statement'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8598, 1519)\n",
      "(2926, 1519)\n",
      "(1267, 1519)\n",
      "(8598,)\n",
      "(2926,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 20.608\n",
      "Saving after new best accuracy : 20.916\n",
      "Saving after new best accuracy : 20.984\n",
      "Saving after new best accuracy : 21.121\n",
      "Saving after new best accuracy : 21.531\n",
      "Saving after new best accuracy : 22.078\n",
      "Saving after new best accuracy : 22.42\n",
      "-- Epoch 50, Train Loss : 27.35636556148529, Test Loss : 1.8112685680389404\n",
      "-- Epoch 100, Train Loss : 26.388538599014282, Test Loss : 1.96233069896698\n",
      "-- Epoch 150, Train Loss : 26.180659413337708, Test Loss : 2.0597145557403564\n",
      "-- Epoch 200, Train Loss : 26.095879077911377, Test Loss : 2.1263034343719482\n",
      "-- Epoch 250, Train Loss : 26.049230933189392, Test Loss : 2.1761624813079834\n",
      "-- Epoch 300, Train Loss : 26.018466353416443, Test Loss : 2.2162811756134033\n",
      "-- Epoch 350, Train Loss : 25.995692372322083, Test Loss : 2.2507376670837402\n",
      "-- Epoch 400, Train Loss : 25.977702379226685, Test Loss : 2.2809743881225586\n",
      "-- Epoch 450, Train Loss : 25.96232783794403, Test Loss : 2.3080976009368896\n",
      "-- Epoch 500, Train Loss : 25.94933521747589, Test Loss : 2.333672523498535\n",
      "-- Epoch 550, Train Loss : 25.93795073032379, Test Loss : 2.3578481674194336\n",
      "-- Epoch 600, Train Loss : 25.927494883537292, Test Loss : 2.381028413772583\n",
      "-- Epoch 650, Train Loss : 25.917956829071045, Test Loss : 2.4036803245544434\n",
      "-- Epoch 700, Train Loss : 25.90857970714569, Test Loss : 2.4257266521453857\n",
      "-- Epoch 750, Train Loss : 25.899983286857605, Test Loss : 2.44732928276062\n",
      "-- Epoch 800, Train Loss : 25.89185857772827, Test Loss : 2.4685986042022705\n",
      "-- Epoch 850, Train Loss : 25.883989810943604, Test Loss : 2.4891140460968018\n",
      "-- Epoch 900, Train Loss : 25.876142144203186, Test Loss : 2.508814811706543\n",
      "-- Epoch 950, Train Loss : 25.868722319602966, Test Loss : 2.5277628898620605\n",
      "-- Epoch 1000, Train Loss : 25.861112356185913, Test Loss : 2.5454587936401367\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 356.47 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([2926])\n",
      "2926 vs 2926\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 32.014 %\n",
      "- Recall : 16.007 %\n",
      "- F1 : 0.21343\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 21.216 %\n",
      "- Recall : 89.718 %\n",
      "- F1 : 0.34317\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 25.275 %\n",
      "- Recall : 4.035 %\n",
      "- F1 : 0.06959\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 42.857 %\n",
      "- Recall : 0.647 %\n",
      "- F1 : 0.01274\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 22.42 %\n",
      "- Precision : 20.227 %\n",
      "- Recall : 18.401 %\n",
      "- F1 : 0.19271\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 22.42, 20.227, 18.401, 0.19271, 32.014, 16.007, 0.21343, 21.216, 89.718, 0.34317, 25.275, 4.035, 0.06959, 0, 0.0, 0, 42.857, 0.647, 0.01274, 0, 0.0, 0, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1267])\n",
      "1267 vs 1267\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 38.017 %\n",
      "- Recall : 18.11 %\n",
      "- F1 : 0.24533\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 20.485 %\n",
      "- Recall : 87.692 %\n",
      "- F1 : 0.33212\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 15.625 %\n",
      "- Recall : 1.984 %\n",
      "- F1 : 0.03521\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 0.476 %\n",
      "- F1 : 0.00948\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 22.099 %\n",
      "- Precision : 29.021 %\n",
      "- Recall : 18.044 %\n",
      "- F1 : 0.22252\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 22.099, 29.021, 18.044, 0.22252, 38.017, 18.11, 0.24533, 20.485, 87.692, 0.33212, 15.625, 1.984, 0.03521, 0, 0.0, 0, 100.0, 0.476, 0.00948, 0, 0.0, 0, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=6, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
