{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"LiarPantsFire-Multi\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/LiarPantsFire_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          statement        label  \\\n",
       "0   2635.json  Says the Annies List political group supports ...        false   \n",
       "1  10540.json  When did the decline of coal start? It started...    half-true   \n",
       "2    324.json  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
       "3   1123.json  Health care reform legislation is likely to ma...        false   \n",
       "4   9028.json  The economic turnaround started at the end of ...    half-true   \n",
       "\n",
       "         tvt2      tvt2_1      tvt2_2      tvt2_3  \n",
       "0  validation  validation    training    training  \n",
       "1    training    training  validation    training  \n",
       "2    training    training  validation  validation  \n",
       "3    training  validation    testting    training  \n",
       "4    training    training    testting    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/liarpantsfire_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 1, 3, 4, 1, 1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4240f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attorney General Eric', 'Supreme Court nominee', 'wildly unpopular', 'Terry McAuliffe', 'For every one', 'takeover of healthcare', 'babies born in', 'and your doctor', '278,000 per job', 'voted six times']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/liarpantsfire_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['statement'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8598, 1519, 1)\n",
      "(2926, 1519, 1)\n",
      "(1267, 1519, 1)\n",
      "(8598,)\n",
      "(2926,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.598\n",
      "Saving after new best accuracy : 25.769\n",
      "Saving after new best accuracy : 26.077\n",
      "Saving after new best accuracy : 26.111\n",
      "Saving after new best accuracy : 26.145\n",
      "-- Epoch 50, Train Loss : 17.784968972206116, Test Loss : 1.7791171073913574\n",
      "-- Epoch 100, Train Loss : 17.772813200950623, Test Loss : 1.7791324853897095\n",
      "-- Epoch 150, Train Loss : 17.765134811401367, Test Loss : 1.7795230150222778\n",
      "-- Epoch 200, Train Loss : 17.759554743766785, Test Loss : 1.7823282480239868\n",
      "-- Epoch 250, Train Loss : 17.7570880651474, Test Loss : 1.7828090190887451\n",
      "-- Epoch 300, Train Loss : 17.75659191608429, Test Loss : 1.7826604843139648\n",
      "-- Epoch 350, Train Loss : 17.75653624534607, Test Loss : 1.7828922271728516\n",
      "-- Epoch 400, Train Loss : 17.754581570625305, Test Loss : 1.7813016176223755\n",
      "-- Epoch 450, Train Loss : 17.753774404525757, Test Loss : 1.7821557521820068\n",
      "-- Epoch 500, Train Loss : 17.753761649131775, Test Loss : 1.7822133302688599\n",
      "-- Epoch 550, Train Loss : 17.753756999969482, Test Loss : 1.782340168952942\n",
      "-- Epoch 600, Train Loss : 17.753754138946533, Test Loss : 1.7824652194976807\n",
      "-- Epoch 650, Train Loss : 17.753752946853638, Test Loss : 1.7825838327407837\n",
      "-- Epoch 700, Train Loss : 17.753751754760742, Test Loss : 1.7826985120773315\n",
      "-- Epoch 750, Train Loss : 17.753751516342163, Test Loss : 1.782805323600769\n",
      "-- Epoch 800, Train Loss : 17.753751516342163, Test Loss : 1.7829052209854126\n",
      "-- Epoch 850, Train Loss : 17.753751516342163, Test Loss : 1.7829957008361816\n",
      "-- Epoch 900, Train Loss : 17.753751516342163, Test Loss : 1.7830829620361328\n",
      "-- Epoch 950, Train Loss : 17.753751516342163, Test Loss : 1.7831623554229736\n",
      "-- Epoch 1000, Train Loss : 17.753751516342163, Test Loss : 1.7832307815551758\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 378.49 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([2926])\n",
      "2926 vs 2926\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 26.208 %\n",
      "- Recall : 32.194 %\n",
      "- F1 : 0.28894\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 24.584 %\n",
      "- Recall : 31.841 %\n",
      "- F1 : 0.27746\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 27.608 %\n",
      "- Recall : 30.175 %\n",
      "- F1 : 0.28835\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 30.565 %\n",
      "- Recall : 19.207 %\n",
      "- F1 : 0.2359\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 22.857 %\n",
      "- Recall : 24.138 %\n",
      "- F1 : 0.2348\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 37.5 %\n",
      "- Recall : 7.087 %\n",
      "- F1 : 0.11921\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 26.145 %\n",
      "- Precision : 28.22 %\n",
      "- Recall : 24.107 %\n",
      "- F1 : 0.26002\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 26.145, 28.22, 24.107, 0.26002, 26.208, 32.194, 0.28894, 24.584, 31.841, 0.27746, 27.608, 30.175, 0.28835, 30.565, 19.207, 0.2359, 22.857, 24.138, 0.2348, 37.5, 7.087, 0.11921, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1267])\n",
      "1267 vs 1267\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 27.551 %\n",
      "- Recall : 31.89 %\n",
      "- F1 : 0.29562\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 25.824 %\n",
      "- Recall : 36.154 %\n",
      "- F1 : 0.30128\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 28.226 %\n",
      "- Recall : 27.778 %\n",
      "- F1 : 0.28\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 23.448 %\n",
      "- Recall : 18.28 %\n",
      "- F1 : 0.20544\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 23.737 %\n",
      "- Recall : 22.381 %\n",
      "- F1 : 0.23039\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 27.778 %\n",
      "- Recall : 4.762 %\n",
      "- F1 : 0.0813\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 26.125 %\n",
      "- Precision : 26.094 %\n",
      "- Recall : 23.541 %\n",
      "- F1 : 0.24752\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 26.125, 26.094, 23.541, 0.24752, 27.551, 31.89, 0.29562, 25.824, 36.154, 0.30128, 28.226, 27.778, 0.28, 23.448, 18.28, 0.20544, 23.737, 22.381, 0.23039, 27.778, 4.762, 0.0813, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=6, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
