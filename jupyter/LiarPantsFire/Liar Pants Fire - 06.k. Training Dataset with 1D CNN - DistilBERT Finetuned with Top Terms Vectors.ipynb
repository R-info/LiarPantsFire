{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"LiarPantsFire-Multi\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/LiarPantsFire_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          statement        label  \\\n",
       "0   2635.json  Says the Annies List political group supports ...        false   \n",
       "1  10540.json  When did the decline of coal start? It started...    half-true   \n",
       "2    324.json  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
       "3   1123.json  Health care reform legislation is likely to ma...        false   \n",
       "4   9028.json  The economic turnaround started at the end of ...    half-true   \n",
       "\n",
       "         tvt2      tvt2_1      tvt2_2      tvt2_3  \n",
       "0  validation  validation    training    training  \n",
       "1    training    training  validation    training  \n",
       "2    training    training  validation  validation  \n",
       "3    training  validation    testting    training  \n",
       "4    training    training    testting    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/liarpantsfire_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 1, 3, 4, 1, 1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0aab2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attorney General Eric', 'Supreme Court nominee', 'wildly unpopular', 'Terry McAuliffe', 'For every one', 'takeover of healthcare', 'babies born in', 'and your doctor', '278,000 per job', 'voted six times']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/liarpantsfire_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['statement'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8598, 1519, 1)\n",
      "(2926, 1519, 1)\n",
      "(1267, 1519, 1)\n",
      "(8598,)\n",
      "(2926,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.256\n",
      "Saving after new best accuracy : 25.53\n",
      "-- Epoch 50, Train Loss : 17.750890970230103, Test Loss : 1.777158498764038\n",
      "-- Epoch 100, Train Loss : 17.744810938835144, Test Loss : 1.7790372371673584\n",
      "-- Epoch 150, Train Loss : 17.744132161140442, Test Loss : 1.7798173427581787\n",
      "-- Epoch 200, Train Loss : 17.743945956230164, Test Loss : 1.780264973640442\n",
      "-- Epoch 250, Train Loss : 17.743873715400696, Test Loss : 1.780596137046814\n",
      "-- Epoch 300, Train Loss : 17.743839263916016, Test Loss : 1.7808618545532227\n",
      "-- Epoch 350, Train Loss : 17.74382197856903, Test Loss : 1.7810864448547363\n",
      "-- Epoch 400, Train Loss : 17.743812441825867, Test Loss : 1.7812888622283936\n",
      "-- Epoch 450, Train Loss : 17.743807435035706, Test Loss : 1.7814844846725464\n",
      "-- Epoch 500, Train Loss : 17.743804216384888, Test Loss : 1.7816615104675293\n",
      "-- Epoch 550, Train Loss : 17.743802785873413, Test Loss : 1.7818304300308228\n",
      "-- Epoch 600, Train Loss : 17.743802189826965, Test Loss : 1.7819852828979492\n",
      "-- Epoch 650, Train Loss : 17.743801712989807, Test Loss : 1.782130241394043\n",
      "-- Epoch 700, Train Loss : 17.743801593780518, Test Loss : 1.7822679281234741\n",
      "-- Epoch 750, Train Loss : 17.743801593780518, Test Loss : 1.7823867797851562\n",
      "-- Epoch 800, Train Loss : 17.743801593780518, Test Loss : 1.7824995517730713\n",
      "-- Epoch 850, Train Loss : 17.743801593780518, Test Loss : 1.7826018333435059\n",
      "-- Epoch 900, Train Loss : 17.743801593780518, Test Loss : 1.7826896905899048\n",
      "-- Epoch 950, Train Loss : 17.743801593780518, Test Loss : 1.782753348350525\n",
      "-- Epoch 1000, Train Loss : 17.743801593780518, Test Loss : 1.7828348875045776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 362.96 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([2926])\n",
      "2926 vs 2926\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 23.74 %\n",
      "- Recall : 26.259 %\n",
      "- F1 : 0.24936\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 26.278 %\n",
      "- Recall : 30.68 %\n",
      "- F1 : 0.28309\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 27.488 %\n",
      "- Recall : 30.526 %\n",
      "- F1 : 0.28928\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 26.685 %\n",
      "- Recall : 19.833 %\n",
      "- F1 : 0.22754\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 22.261 %\n",
      "- Recall : 27.586 %\n",
      "- F1 : 0.24639\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 44.186 %\n",
      "- Recall : 7.48 %\n",
      "- F1 : 0.12795\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 25.53 %\n",
      "- Precision : 28.44 %\n",
      "- Recall : 23.727 %\n",
      "- F1 : 0.25871\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 25.53, 28.44, 23.727, 0.25871, 23.74, 26.259, 0.24936, 26.278, 30.68, 0.28309, 27.488, 30.526, 0.28928, 26.685, 19.833, 0.22754, 22.261, 27.586, 0.24639, 44.186, 7.48, 0.12795, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1267])\n",
      "1267 vs 1267\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 27.419 %\n",
      "- Recall : 33.465 %\n",
      "- F1 : 0.30142\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 28.105 %\n",
      "- Recall : 33.077 %\n",
      "- F1 : 0.30389\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 26.119 %\n",
      "- Recall : 27.778 %\n",
      "- F1 : 0.26923\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 30.303 %\n",
      "- Recall : 21.505 %\n",
      "- F1 : 0.25157\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 22.609 %\n",
      "- Recall : 24.762 %\n",
      "- F1 : 0.23636\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 33.333 %\n",
      "- Recall : 6.667 %\n",
      "- F1 : 0.11111\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 26.835 %\n",
      "- Precision : 27.981 %\n",
      "- Recall : 24.542 %\n",
      "- F1 : 0.26149\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 26.835, 27.981, 24.542, 0.26149, 27.419, 33.465, 0.30142, 28.105, 33.077, 0.30389, 26.119, 27.778, 0.26923, 30.303, 21.505, 0.25157, 22.609, 24.762, 0.23636, 33.333, 6.667, 0.11111, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=6, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
