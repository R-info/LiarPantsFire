{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"LiarPantsFire-Multi\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/LiarPantsFire_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          statement        label  \\\n",
       "0   2635.json  Says the Annies List political group supports ...        false   \n",
       "1  10540.json  When did the decline of coal start? It started...    half-true   \n",
       "2    324.json  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
       "3   1123.json  Health care reform legislation is likely to ma...        false   \n",
       "4   9028.json  The economic turnaround started at the end of ...    half-true   \n",
       "\n",
       "         tvt2      tvt2_1      tvt2_2      tvt2_3  \n",
       "0  validation  validation    training    training  \n",
       "1    training    training  validation    training  \n",
       "2    training    training  validation  validation  \n",
       "3    training  validation    testting    training  \n",
       "4    training    training    testting    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/liarpantsfire_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 1, 3, 4, 1, 1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attorney General Eric', 'Supreme Court nominee', 'wildly unpopular', 'Terry McAuliffe', 'For every one', 'takeover of healthcare', 'babies born in', 'and your doctor', '278,000 per job', 'voted six times']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/liarpantsfire_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['statement'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8598, 1519)\n",
      "(2926, 1519)\n",
      "(1267, 1519)\n",
      "(8598,)\n",
      "(2926,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.222\n",
      "Saving after new best accuracy : 25.598\n",
      "Saving after new best accuracy : 25.632\n",
      "Saving after new best accuracy : 25.666\n",
      "-- Epoch 50, Train Loss : 0.015667052619392052, Test Loss : 6.279645919799805\n",
      "-- Epoch 100, Train Loss : 0.008376867548577138, Test Loss : 7.531083583831787\n",
      "Saving after new best accuracy : 25.701\n",
      "-- Epoch 150, Train Loss : 0.008877963706254377, Test Loss : 8.135997772216797\n",
      "-- Epoch 200, Train Loss : 0.00872383807791266, Test Loss : 8.527119636535645\n",
      "Saving after new best accuracy : 25.735\n",
      "Saving after new best accuracy : 25.769\n",
      "-- Epoch 250, Train Loss : 0.008232688619955297, Test Loss : 8.891427993774414\n",
      "Saving after new best accuracy : 25.803\n",
      "Saving after new best accuracy : 25.837\n",
      "-- Epoch 300, Train Loss : 0.007700663826199161, Test Loss : 9.372645378112793\n",
      "-- Epoch 350, Train Loss : 0.007763814305008054, Test Loss : 9.837421417236328\n",
      "-- Epoch 400, Train Loss : 0.007042293380834508, Test Loss : 10.529095649719238\n",
      "-- Epoch 450, Train Loss : 0.0068664496770907135, Test Loss : 11.251422882080078\n",
      "-- Epoch 500, Train Loss : 0.006024487132947343, Test Loss : 12.091580390930176\n",
      "-- Epoch 550, Train Loss : 0.0057990754276247, Test Loss : 13.011347770690918\n",
      "-- Epoch 600, Train Loss : 0.005730748641331829, Test Loss : 13.790168762207031\n",
      "-- Epoch 650, Train Loss : 0.006144401576996472, Test Loss : 14.517271041870117\n",
      "-- Epoch 700, Train Loss : 0.0058532467324190485, Test Loss : 15.664973258972168\n",
      "-- Epoch 750, Train Loss : 0.0056213700276956935, Test Loss : 16.679107666015625\n",
      "-- Epoch 800, Train Loss : 0.005595092330894003, Test Loss : 17.353511810302734\n",
      "-- Epoch 850, Train Loss : 0.006434344220402677, Test Loss : 18.384540557861328\n",
      "-- Epoch 900, Train Loss : 0.005580639132270332, Test Loss : 19.21281623840332\n",
      "-- Epoch 950, Train Loss : 0.005556245984706887, Test Loss : 19.909101486206055\n",
      "-- Epoch 1000, Train Loss : 0.0055380982380921345, Test Loss : 20.480207443237305\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 360.45 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([2926])\n",
      "2926 vs 2926\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 24.121 %\n",
      "- Recall : 27.158 %\n",
      "- F1 : 0.2555\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 25.341 %\n",
      "- Recall : 30.846 %\n",
      "- F1 : 0.27823\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 28.295 %\n",
      "- Recall : 28.246 %\n",
      "- F1 : 0.2827\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 28.492 %\n",
      "- Recall : 21.294 %\n",
      "- F1 : 0.24373\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 23.211 %\n",
      "- Recall : 28.664 %\n",
      "- F1 : 0.25651\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 34.848 %\n",
      "- Recall : 9.055 %\n",
      "- F1 : 0.14375\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 25.837 %\n",
      "- Precision : 27.385 %\n",
      "- Recall : 24.21 %\n",
      "- F1 : 0.257\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 25.837, 27.385, 24.21, 0.257, 24.121, 27.158, 0.2555, 25.341, 30.846, 0.27823, 28.295, 28.246, 0.2827, 28.492, 21.294, 0.24373, 23.211, 28.664, 0.25651, 34.848, 9.055, 0.14375, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1267])\n",
      "1267 vs 1267\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 27.848 %\n",
      "- Recall : 34.646 %\n",
      "- F1 : 0.30877\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 27.619 %\n",
      "- Recall : 33.462 %\n",
      "- F1 : 0.30261\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 27.778 %\n",
      "- Recall : 27.778 %\n",
      "- F1 : 0.27778\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 29.771 %\n",
      "- Recall : 20.968 %\n",
      "- F1 : 0.24606\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 23.556 %\n",
      "- Recall : 25.238 %\n",
      "- F1 : 0.24368\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 28.571 %\n",
      "- Recall : 7.619 %\n",
      "- F1 : 0.1203\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 27.23 %\n",
      "- Precision : 27.524 %\n",
      "- Recall : 24.952 %\n",
      "- F1 : 0.26175\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 27.23, 27.524, 24.952, 0.26175, 27.848, 34.646, 0.30877, 27.619, 33.462, 0.30261, 27.778, 27.778, 0.27778, 29.771, 20.968, 0.24606, 23.556, 25.238, 0.24368, 28.571, 7.619, 0.1203, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=6, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
