{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"LiarPantsFire-Multi\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/LiarPantsFire_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          statement        label  \\\n",
       "0   2635.json  Says the Annies List political group supports ...        false   \n",
       "1  10540.json  When did the decline of coal start? It started...    half-true   \n",
       "2    324.json  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
       "3   1123.json  Health care reform legislation is likely to ma...        false   \n",
       "4   9028.json  The economic turnaround started at the end of ...    half-true   \n",
       "\n",
       "         tvt2      tvt2_1      tvt2_2      tvt2_3  \n",
       "0  validation  validation    training    training  \n",
       "1    training    training  validation    training  \n",
       "2    training    training  validation  validation  \n",
       "3    training  validation    testting    training  \n",
       "4    training    training    testting    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/liarpantsfire_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 1, 3, 4, 1, 1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attorney General Eric', 'Supreme Court nominee', 'wildly unpopular', 'Terry McAuliffe', 'For every one', 'takeover of healthcare', 'babies born in', 'and your doctor', '278,000 per job', 'voted six times']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/liarpantsfire_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['statement'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8598, 1519)\n",
      "(2926, 1519)\n",
      "(1267, 1519)\n",
      "(8598,)\n",
      "(2926,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.871\n",
      "Saving after new best accuracy : 25.906\n",
      "Saving after new best accuracy : 25.974\n",
      "Saving after new best accuracy : 26.042\n",
      "Saving after new best accuracy : 26.077\n",
      "Saving after new best accuracy : 26.145\n",
      "Saving after new best accuracy : 26.179\n",
      "Saving after new best accuracy : 26.213\n",
      "-- Epoch 50, Train Loss : 0.06141416827449575, Test Loss : 5.570278167724609\n",
      "-- Epoch 100, Train Loss : 0.011505803791806102, Test Loss : 7.397836685180664\n",
      "-- Epoch 150, Train Loss : 0.008545928731109598, Test Loss : 8.372398376464844\n",
      "-- Epoch 200, Train Loss : 0.007675242097320734, Test Loss : 9.022517204284668\n",
      "-- Epoch 250, Train Loss : 0.007699418458742002, Test Loss : 9.414311408996582\n",
      "-- Epoch 300, Train Loss : 0.0072293318100946635, Test Loss : 9.847382545471191\n",
      "-- Epoch 350, Train Loss : 0.0066933612533830456, Test Loss : 10.240022659301758\n",
      "-- Epoch 400, Train Loss : 0.007006023076087331, Test Loss : 10.756158828735352\n",
      "-- Epoch 450, Train Loss : 0.006280780808879172, Test Loss : 11.326613426208496\n",
      "-- Epoch 500, Train Loss : 0.006134034373758368, Test Loss : 11.93005084991455\n",
      "-- Epoch 550, Train Loss : 0.00592840669125394, Test Loss : 12.681126594543457\n",
      "-- Epoch 600, Train Loss : 0.005778807948374265, Test Loss : 13.508186340332031\n",
      "-- Epoch 650, Train Loss : 0.0057792266641207846, Test Loss : 14.199402809143066\n",
      "-- Epoch 700, Train Loss : 0.005645584855187735, Test Loss : 14.991021156311035\n",
      "-- Epoch 750, Train Loss : 0.005567750242379432, Test Loss : 15.817648887634277\n",
      "-- Epoch 800, Train Loss : 0.005554845965861865, Test Loss : 16.353918075561523\n",
      "-- Epoch 850, Train Loss : 0.007623661268791437, Test Loss : 16.99213218688965\n",
      "-- Epoch 900, Train Loss : 0.005549065626398342, Test Loss : 17.726503372192383\n",
      "-- Epoch 950, Train Loss : 0.00549962653094388, Test Loss : 18.536277770996094\n",
      "-- Epoch 1000, Train Loss : 0.00547998605615338, Test Loss : 19.12636375427246\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 354.92 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([2926])\n",
      "2926 vs 2926\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 26.263 %\n",
      "- Recall : 32.734 %\n",
      "- F1 : 0.29143\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 25.352 %\n",
      "- Recall : 29.851 %\n",
      "- F1 : 0.27418\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 27.63 %\n",
      "- Recall : 30.877 %\n",
      "- F1 : 0.29163\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 30.721 %\n",
      "- Recall : 20.459 %\n",
      "- F1 : 0.24561\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 21.942 %\n",
      "- Recall : 24.353 %\n",
      "- F1 : 0.23085\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 34.615 %\n",
      "- Recall : 7.087 %\n",
      "- F1 : 0.11765\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 26.213 %\n",
      "- Precision : 27.754 %\n",
      "- Recall : 24.227 %\n",
      "- F1 : 0.25871\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 26.213, 27.754, 24.227, 0.25871, 26.263, 32.734, 0.29143, 25.352, 29.851, 0.27418, 27.63, 30.877, 0.29163, 30.721, 20.459, 0.24561, 21.942, 24.353, 0.23085, 34.615, 7.087, 0.11765, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1267])\n",
      "1267 vs 1267\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 26.936 %\n",
      "- Recall : 31.496 %\n",
      "- F1 : 0.29038\n",
      "\n",
      "Class half-true Evaluation\n",
      "- Precision : 26.549 %\n",
      "- Recall : 34.615 %\n",
      "- F1 : 0.3005\n",
      "\n",
      "Class mostly-true Evaluation\n",
      "- Precision : 28.063 %\n",
      "- Recall : 28.175 %\n",
      "- F1 : 0.28119\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 22.876 %\n",
      "- Recall : 18.817 %\n",
      "- F1 : 0.20649\n",
      "\n",
      "Class barely-true Evaluation\n",
      "- Precision : 23.671 %\n",
      "- Recall : 23.333 %\n",
      "- F1 : 0.23501\n",
      "\n",
      "Class pants-fire Evaluation\n",
      "- Precision : 27.778 %\n",
      "- Recall : 4.762 %\n",
      "- F1 : 0.0813\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 26.046 %\n",
      "- Precision : 25.979 %\n",
      "- Recall : 23.533 %\n",
      "- F1 : 0.24696\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,half-true,,,mostly-true,,,true,,,barely-true,,,pants-fire,,,\n",
      "LiarPantsFire-Multi_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 26.046, 25.979, 23.533, 0.24696, 26.936, 31.496, 0.29038, 26.549, 34.615, 0.3005, 28.063, 28.175, 0.28119, 22.876, 18.817, 0.20649, 23.671, 23.333, 0.23501, 27.778, 4.762, 0.0813, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=6, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
